"""
AST-based Lua source transformer
This fixes Lua source code based on AST analysis findings
"""

import re
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple, Set
import shutil

from ast_analyzer import analyze_file, ASTAnalyzer, Scope
from models import Finding


@dataclass
class SourceEdit:
    """A source code edit with character positions."""
    start_char: int      # start character offset in source
    end_char: int        # end character offset (exclusive)
    replacement: str     # replacement text
    priority: int = 0    # higher priority edits applied first


class ASTTransformer:
    """Transform Lua source using AST-based analysis."""

    def __init__(self):
        self.source: str = ""
        self.edits: List[SourceEdit] = []
        self.file_path: Optional[Path] = None
        self.analyzer: Optional[ASTAnalyzer] = None

    def transform_file(self, file_path: Path, backup: bool = True, dry_run: bool = False,
                       fix_debug: bool = False, fix_yellow: bool = False,
                       experimental: bool = False, fix_nil: bool = False,
                       remove_dead_code: bool = False) -> Tuple[bool, str, int]:
        """
        Transform a file based on findings.
        Returns (was_modified, new_content, edit_count).
        
        Args:
            fix_nil: If True, auto-fix safe nil access patterns
            remove_dead_code: If True, remove 100% safe dead code (after return, if false, etc.)
        """
        self.file_path = file_path
        self.edits = []
        self.experimental = experimental
        self.fix_nil = fix_nil
        self.remove_dead_code = remove_dead_code

        # run analyzer
        self.analyzer = ASTAnalyzer()
        findings = self.analyzer.analyze_file(file_path)

        # get source from analyzer
        self.source = self.analyzer.source

        # filter to fixable severities
        allowed_severities = {'GREEN'}
        if fix_yellow:
            allowed_severities.add('YELLOW')
        if fix_debug:
            allowed_severities.add('DEBUG')

        fixable = [f for f in findings if f.severity in allowed_severities]
        
        # add experimental fixes (string_concat_in_loop) if enabled
        # only add if not already included via fix_yellow
        if experimental and not fix_yellow:
            experimental_fixes = [f for f in findings 
                                  if f.pattern_name == 'string_concat_in_loop' 
                                  and f.severity == 'YELLOW']
            fixable.extend(experimental_fixes)
        
        # add safe nil fixes if enabled
        if fix_nil:
            nil_fixes = [f for f in findings 
                        if f.pattern_name == 'potential_nil_access'
                        and f.details.get('is_safe_to_fix', False)]
            # only add if not already in fixable
            existing_lines = {f.line_num for f in fixable}
            for nf in nil_fixes:
                if nf.line_num not in existing_lines:
                    fixable.append(nf)
        
        # add safe dead code removal if enabled
        if remove_dead_code:
            dead_code_fixes = [f for f in findings
                              if f.pattern_name.startswith('dead_code_')
                              and f.details.get('is_safe_to_remove', False)]
            existing_lines = {f.line_num for f in fixable}
            for df in dead_code_fixes:
                if df.line_num not in existing_lines:
                    fixable.append(df)

        if not fixable:
            return False, self.source, 0

        # generate edits for each finding
        for finding in fixable:
            self._generate_edits(finding)

        if not self.edits:
            return False, self.source, 0

        edit_count = len(self.edits)

        # apply edits
        new_content = self._apply_edits()

        if new_content == self.source:
            return False, self.source, 0

        if not dry_run:
            if backup:
                # use .alao-bak extension to distinguish from mod author backups
                backup_path = file_path.with_suffix(file_path.suffix + '.alao-bak')
                if not backup_path.exists():
                    shutil.copy2(file_path, backup_path)

            file_path.write_text(new_content, encoding='latin-1')

        return True, new_content, edit_count

    def _generate_edits(self, finding: Finding):
        """Generate source edits for a finding."""
        pattern = finding.pattern_name

        if pattern == 'table_insert_append':
            self._edit_table_insert(finding)
        elif pattern == 'table_getn':
            self._edit_table_getn(finding)
        elif pattern == 'string_len':
            self._edit_string_len(finding)
        elif pattern == 'math_pow_simple':
            self._edit_math_pow(finding)
        elif pattern == 'debug_statement':
            self._edit_debug_statement(finding)
        elif pattern == 'uncached_globals_summary':
            self._edit_uncached_globals(finding)
        elif pattern == 'string_concat_in_loop':
            if getattr(self, 'experimental', False):
                self._edit_string_concat_in_loop(finding)
        elif pattern == 'potential_nil_access':
            if getattr(self, 'fix_nil', False):
                self._edit_nil_access(finding)
        elif pattern.startswith('dead_code_'):
            if getattr(self, 'remove_dead_code', False):
                self._edit_dead_code(finding)
        elif pattern.startswith('repeated_'):
            self._edit_repeated_calls(finding)


    # Edit methods using AST positions

    def _edit_table_insert(self, finding: Finding):
        """Convert table.insert(t, v) to t[#t+1] = v."""
        node = finding.details.get('node')
        if not node:
            return

        table_name = finding.details.get('table', '')
        if not table_name:
            return

        # get position from node tokens
        start, end = self._get_node_span(node)
        if start is None:
            return

        # extract value from source
        call_text = self.source[start:end]
        value = self._extract_table_insert_value(call_text, table_name)
        if not value:
            return

        replacement = f'{table_name}[#{table_name}+1] = {value}'

        self.edits.append(SourceEdit(
            start_char=start,
            end_char=end,
            replacement=replacement,
        ))

    def _extract_table_insert_value(self, call_text: str, table_name: str) -> Optional[str]:
        """Extract the value argument from table.insert(t, v) call text."""
        # find opening paren
        paren_start = call_text.find('(')
        if paren_start == -1:
            return None

        # find comma after table name
        comma_pos = call_text.find(',', paren_start)
        if comma_pos == -1:
            return None

        value_start = comma_pos + 1

        # find matching closing paren with proper tracking
        depth = 1
        brace_depth = 0
        bracket_depth = 0
        in_string = False
        string_char = None
        i = paren_start + 1

        while i < len(call_text) and depth > 0:
            c = call_text[i]

            if not in_string:
                if c in ('"', "'"):
                    in_string = True
                    string_char = c
                elif c == '(':
                    depth += 1
                elif c == ')':
                    depth -= 1
                elif c == '{':
                    brace_depth += 1
                elif c == '}':
                    brace_depth -= 1
                elif c == '[':
                    bracket_depth += 1
                elif c == ']':
                    bracket_depth -= 1
            else:
                if c == string_char and (i == 0 or call_text[i - 1] != '\\'):
                    in_string = False

            i += 1

        if depth != 0:
            return None

        value = call_text[value_start:i - 1].strip()
        return value

    def _edit_table_getn(self, finding: Finding):
        """Convert table.getn(t) to #t."""
        node = finding.details.get('node')
        if not node:
            return

        table_name = finding.details.get('table', '')
        if not table_name:
            return

        start, end = self._get_node_span(node)
        if start is None:
            return

        self.edits.append(SourceEdit(
            start_char=start,
            end_char=end,
            replacement=f'#{table_name}',
        ))

    def _edit_string_len(self, finding: Finding):
        """Convert string.len(s) to #s."""
        node = finding.details.get('node')
        if not node:
            return

        str_name = finding.details.get('string', '')
        if not str_name:
            return

        start, end = self._get_node_span(node)
        if start is None:
            return

        self.edits.append(SourceEdit(
            start_char=start,
            end_char=end,
            replacement=f'#{str_name}',
        ))

    def _edit_math_pow(self, finding: Finding):
        """Convert math.pow(x, n) to x^n or x*x*..."""
        node = finding.details.get('node')
        if not node:
            return

        base = finding.details.get('base', '')
        exp = finding.details.get('exponent')
        pow_type = finding.details.get('type')

        if not base:
            return

        start, end = self._get_node_span(node)
        if start is None:
            return

        if pow_type == 'sqrt':
            replacement = f'{base}^0.5'
        elif pow_type == 'power' and isinstance(exp, int):
            replacement = '*'.join([base] * exp)
        else:
            return

        self.edits.append(SourceEdit(
            start_char=start,
            end_char=end,
            replacement=replacement,
        ))

    def _edit_debug_statement(self, finding: Finding):
        """Comment out debug statement (handles multi-line calls)."""
        node = finding.details.get('node')

        # control flow keywords that shouldn't be commented out
        control_flow_keywords = ['if ', 'then ', 'else', 'elseif ', 'end', 'for ', 'while ',
                                 'do ', 'repeat', 'until ', 'function ', 'return ']

        if node:
            # use AST node to get full span of call
            start_char, end_char = self._get_node_span(node)
            if start_char is not None:
                # find all lines this call spans
                start_line = self.source[:start_char].count('\n') + 1
                end_line = self.source[:end_char].count('\n') + 1

                # expression continuations - if prev line ends with these, call is part of expr
                expr_continuations = [' and', ' or', '(', ',', '=', '{', '[']

                if start_line > 1:
                    prev_line_start, prev_line_end = self._get_line_span(start_line - 1)
                    if prev_line_start is not None:
                        prev_line = self.source[prev_line_start:prev_line_end].rstrip()
                        for cont in expr_continuations:
                            if prev_line.endswith(cont):
                                return  # skip - this is part of an expression

                # collect all lines and check them ALL for control flow
                lines_to_comment = []
                has_control_flow = False

                for line_num in range(start_line, end_line + 1):
                    line_start, line_end = self._get_line_span(line_num)
                    if line_start is None:
                        continue

                    line = self.source[line_start:line_end]
                    stripped = line.lstrip()

                    # skip if already commented
                    if stripped.startswith('--'):
                        continue

                    # check for control flow on ANY line of the multi-line statement
                    for kw in control_flow_keywords:
                        if kw in stripped.lower():
                            has_control_flow = True
                            break

                    lines_to_comment.append((line_num, line_start, line_end, line, stripped))

                # if ANY line has control flow, skip the ENTIRE statement
                if has_control_flow:
                    return

                # comment out all lines
                for line_num, line_start, line_end, line, stripped in lines_to_comment:
                    indent = line[:len(line) - len(stripped)]
                    new_line = f'{indent}-- {stripped}'

                    self.edits.append(SourceEdit(
                        start_char=line_start,
                        end_char=line_end,
                        replacement=new_line,
                        priority=200,  # high priority to override variable replacements inside debug calls
                    ))
                return

        # fallback to single line if no node
        line_num = finding.line_num
        start, end = self._get_line_span(line_num)
        if start is None:
            return

        # check for expression continuation on prev line
        expr_continuations = [' and', ' or', '(', ',', '=', '{', '[']
        if line_num > 1:
            prev_line_start, prev_line_end = self._get_line_span(line_num - 1)
            if prev_line_start is not None:
                prev_line = self.source[prev_line_start:prev_line_end].rstrip()
                for cont in expr_continuations:
                    if prev_line.endswith(cont):
                        return  # skip - part of expression

        line = self.source[start:end]
        stripped = line.lstrip()

        if stripped.startswith('--'):
            return

        # skip lines with control flow
        for kw in control_flow_keywords:
            if kw in stripped.lower():
                return

        indent = line[:len(line) - len(stripped)]
        new_line = f'{indent}-- {stripped}'

        self.edits.append(SourceEdit(
            start_char=start,
            end_char=end,
            replacement=new_line,
            priority=200,
        ))

    def _edit_nil_access(self, finding: Finding):
        """
        Wrap unsafe nil access with if-then guard.
        
        Before:
            local obj = level.object_by_id(id)
            obj:set_visual("stalker")
            
        After:
            local obj = level.object_by_id(id)
            if obj then
                obj:set_visual("stalker")
            end
            
        Only applies to safe-to-fix cases (immediately after assignment).
        Only wraps SINGLE lines to avoid corrupting nested control structures.
        
        IMPORTANT: Does NOT wrap lines containing 'local' declarations,
        as that would change variable scope and break code that uses
        the variable outside the if block.
        """
        details = finding.details
        
        # only fix safe cases
        if not details.get('is_safe_to_fix', False):
            return
        
        var_name = details.get('var_name')
        assign_line = details.get('assign_line')
        access_line = finding.line_num
        
        if not var_name or not assign_line:
            return
        
        # get the access line
        access_line_start, access_line_end = self._get_line_span(access_line)
        if access_line_start is None:
            return
        
        access_line_text = self.source[access_line_start:access_line_end]
        stripped_access = access_line_text.strip()
        
        # SAFETY CHECK: don't wrap lines with local declarations
        if stripped_access.startswith('local '):
            return
        
        # SAFETY CHECK: don't wrap control flow statements (if, for, while, etc.)
        # these have complex nested structures that can get corrupted
        control_keywords = ('if ', 'if(', 'for ', 'while ', 'repeat', 'function ', 'function(')
        if any(stripped_access.startswith(kw) for kw in control_keywords):
            return
        
        # SAFETY CHECK: don't wrap incomplete statements (multi-line function calls, etc.)
        # check for unbalanced parentheses - if line has more '(' than ')', it continues on next line
        open_parens = stripped_access.count('(')
        close_parens = stripped_access.count(')')
        if open_parens > close_parens:
            return
        
        # SAFETY CHECK: don't wrap lines ending with opening constructs
        rstripped = stripped_access.rstrip()
        if rstripped.endswith('(') or rstripped.endswith(',') or rstripped.endswith('..'):
            return
        
        # SAFETY CHECK: don't wrap if next line also uses the same variable directly
        # this would result in partial protection (first line guarded, second line crashes)
        next_line_start, next_line_end = self._get_line_span(access_line + 1)
        if next_line_start is not None:
            next_line_text = self.source[next_line_start:next_line_end].strip()
            # check if next line starts with VAR: (direct method call on same variable)
            if next_line_text.startswith(f'{var_name}:'):
                return
        
        # determine indent from the access line
        indent = ''
        for ch in access_line_text:
            if ch in ' \t':
                indent += ch
            else:
                break
        
        # ONLY wrap this single line - don't try to wrap multiple lines
        # Multi-line wrapping is error-prone with nested structures
        wrapped_content = stripped_access
        
        # build the replacement
        new_content = f'{indent}if {var_name} then\n'
        new_content += f'{indent}    {wrapped_content}\n'
        new_content += f'{indent}end'
        
        # preserve trailing newline if original had one
        if access_line_text.endswith('\n'):
            new_content += '\n'
        
        self.edits.append(SourceEdit(
            start_char=access_line_start,
            end_char=access_line_end,
            replacement=new_content,
            priority=50,
        ))

    def _edit_dead_code(self, finding: Finding):
        """
        Remove dead code that is 100% safe to remove.
        
        Handles:
        - Code after unconditional return
        - Code after break in loops
        - if false then ... end blocks
        - while false do ... end loops
        """
        details = finding.details
        
        # only remove if marked as safe
        if not details.get('is_safe_to_remove', False):
            return
        
        dead_type = details.get('dead_type', '')
        start_line = details.get('start_line', 0)
        end_line = details.get('end_line', 0)
        
        if not start_line or not end_line:
            return
        
        # get the character positions for the lines to remove
        start_pos, _ = self._get_line_span(start_line)
        _, end_pos = self._get_line_span(end_line)
        
        if start_pos is None or end_pos is None:
            return
        
        # determine what to replace with
        if dead_type in ('after_return', 'after_break'):
            # remove the dead statements entirely
            # but preserve any trailing newline to keep formatting
            replacement = ''
        elif dead_type in ('if_false', 'while_false'):
            # remove the entire if/while block
            # check if there's only whitespace before on the same line
            line_content = self.source[start_pos:end_pos]
            
            # preserve indentation context - just remove the block
            replacement = ''
        else:
            return
        
        self.edits.append(SourceEdit(
            start_char=start_pos,
            end_char=end_pos,
            replacement=replacement,
            priority=10,  # high priority - remove dead code first
        ))

    def _edit_string_concat_in_loop(self, finding: Finding):
        """
        Transform string concatenation in loops to table.concat pattern.
        
        Before:
            local result = ""
            for i = 1, 10 do
                result = result .. get_part(i)
            end
            
        After:
            local _result_parts = {}
            for i = 1, 10 do
                _result_parts[#_result_parts+1] = get_part(i)
            end
            local result = table.concat(_result_parts)
        """
        details = finding.details
        var = details.get('variable')
        init_line = details.get('init_line')
        loop_start = details.get('loop_start')
        loop_end = details.get('loop_end')
        concat_lines = details.get('concat_lines', [])
        is_safe = details.get('is_safe', False)
        
        if not var or not init_line or not loop_end or not concat_lines:
            return
        
        if not is_safe:
            return  # only transform safe patterns
        
        # skip one-liner loops (loop start == loop end)
        if loop_start == loop_end:
            return  # one-liner loop, too complex to transform safely
        
        # skip if any concat is on same line as loop start or loop end (embedded/one-liner)
        for concat_line in concat_lines:
            if concat_line == loop_start or concat_line == loop_end:
                return  # concat embedded in loop header/footer, skip
        
        # Bug #32 fix: Additional check - verify concat lines don't contain loop keywords
        # This catches one-liners that the AST might report with different start/end lines
        for concat_line in concat_lines:
            line_start, line_end = self._get_line_span(concat_line)
            if line_start is not None:
                line_text = self.source[line_start:line_end]
                # if the concat line contains 'for ' and ' end', it's a one-liner loop
                if re.search(r'\bfor\b.*\bend\b', line_text):
                    return  # one-liner loop detected via text analysis
                # if line contains 'for ' at all, it's embedded in loop header
                if re.search(r'\bfor\s+', line_text):
                    return  # embedded in for header
        
        parts_var = f'_{var}_parts'
        
        # VALIDATION PHASE: check all lines can be transformed before making any edits
        
        # validate init line
        init_start, init_end = self._get_line_span(init_line)
        if init_start is None:
            return
        
        init_text = self.source[init_start:init_end]
        indent = self._get_indent_at_line(init_line)
        
        # validate all concat lines match the expected pattern
        concat_replacements = []
        for concat_line in concat_lines:
            line_start, line_end = self._get_line_span(concat_line)
            if line_start is None:
                return  # can't find line, abort
            
            line_text = self.source[line_start:line_end]
            line_indent = self._get_indent_at_line(concat_line)
            
            # pattern: var = var .. expr (must be the whole line content, not embedded)
            concat_pattern = re.compile(
                rf'^(\s*){re.escape(var)}\s*=\s*{re.escape(var)}\s*\.\.\s*(.+)$',
                re.DOTALL
            )
            match = concat_pattern.match(line_text.rstrip('\n\r'))
            if not match:
                return  # pattern not on its own line, abort entire transformation
            
            expr = match.group(2).rstrip()
            
            # Bug #31 fix: check if expr references the variable itself
            # e.g. (var == "" and "" or ", ") - this would break after transformation
            # because 'var' won't exist until after table.concat
            if re.search(rf'\b{re.escape(var)}\b', expr):
                # try to replace common patterns like (var == "" and X or Y) with (#parts == 0 and X or Y)
                empty_check = re.compile(
                    rf'\(\s*{re.escape(var)}\s*==\s*""\s+and\s+',
                    re.IGNORECASE
                )
                if empty_check.search(expr):
                    # replace var == "" with #parts_var == 0
                    expr = re.sub(
                        rf'\b{re.escape(var)}\s*==\s*""',
                        f'#{parts_var} == 0',
                        expr
                    )
                else:
                    # can't safely transform, abort
                    return
            
            new_line = f'{line_indent}{parts_var}[#{parts_var}+1] = {expr}\n'
            concat_replacements.append((line_start, line_end, new_line))
        
        # validate loop end line
        end_line_end = self._get_line_end(loop_end)
        if end_line_end is None:
            return
        
        # EDIT PHASE: all validations passed, now add edits
        
        # step 1: replace initialization line
        stripped = init_text.strip()
        if stripped.startswith('local '):
            new_init = f'{indent}local {parts_var} = {{}}\n'
        else:
            new_init = f'{indent}{parts_var} = {{}}\n'
        
        self.edits.append(SourceEdit(
            start_char=init_start,
            end_char=init_end,
            replacement=new_init,
            priority=50,
        ))
        
        # step 2: replace each concat line
        for line_start, line_end, new_line in concat_replacements:
            self.edits.append(SourceEdit(
                start_char=line_start,
                end_char=line_end,
                replacement=new_line,
                priority=50,
            ))
        
        # step 3: add table.concat after loop ends
        concat_decl = f'\n{indent}local {var} = table.concat({parts_var})'
        
        self.edits.append(SourceEdit(
            start_char=end_line_end,
            end_char=end_line_end,
            replacement=concat_decl,
            priority=50,
        ))

    def _edit_uncached_globals(self, finding: Finding):
        """Add local caching for globals at function start."""
        details = finding.details
        globals_info = details.get('globals_info', {})
        scope = details.get('scope')

        if not globals_info or not scope:
            return

        # build cache declarations and track replacements
        cache_lines = []
        replacements: Dict[str, str] = {}

        for name in sorted(globals_info.keys()):
            if '.' in name:
                module, func = name.split('.', 1)
                cache_name = f'{module}_{func}'
            else:
                cache_name = f'g_{name}'

            cache_lines.append(f'local {cache_name} = {name}')
            replacements[name] = cache_name

        if not cache_lines:
            return

        # find insertion point - after function definition line
        insert_pos = self._get_line_end(scope.start_line)
        if insert_pos is None:
            return

        # get indentation
        indent = self._get_indent_at_line(scope.start_line + 1)
        if not indent:
            indent = '\t'

        # build cache block
        cache_block = '\n' + '\n'.join(f'{indent}{line}' for line in cache_lines)

        self.edits.append(SourceEdit(
            start_char=insert_pos,
            end_char=insert_pos,
            replacement=cache_block,
            priority=100,
        ))

        # replace usages using AST node positions
        for name, calls in globals_info.items():
            new_name = replacements.get(name)
            if not new_name:
                continue

            for call in calls:
                node = call.node
                if not node:
                    continue

                # for calls like pairs(), ipairs() - replace the function name part
                if '.' not in name:
                    # bare global - find and replace just the name
                    start, end = self._get_call_func_span(node, name)
                else:
                    # module.func - replace the whole func reference
                    start, end = self._get_call_func_span(node, name)

                if start is None:
                    continue

                self.edits.append(SourceEdit(
                    start_char=start,
                    end_char=end,
                    replacement=new_name,
                ))

    def _edit_repeated_calls(self, finding: Finding):
        """Add caching for repeated expensive calls."""
        details = finding.details
        calls = details.get('calls', [])
        scope = details.get('scope')
        suggestion = details.get('suggestion', '')

        if not calls or not scope:
            return

        pattern = finding.pattern_name

        # determine cache variable name and cache line
        if pattern == 'repeated_db_actor':
            cache_line = 'local actor = db.actor'
            new_name = 'actor'
            call_pattern = 'db.actor'
        elif pattern == 'repeated_time_global':
            cache_line = 'local tg = time_global()'
            new_name = 'tg'
            call_pattern = 'time_global()'
        elif pattern == 'repeated_alife':
            cache_line = 'local sim = alife()'
            new_name = 'sim'
            call_pattern = 'alife()'
        elif pattern == 'repeated_system_ini':
            cache_line = 'local ini = system_ini()'
            new_name = 'ini'
            call_pattern = 'system_ini()'
        elif pattern == 'repeated_device':
            cache_line = 'local dev = device()'
            new_name = 'dev'
            call_pattern = 'device()'
        elif pattern == 'repeated_get_console':
            cache_line = 'local console = get_console()'
            new_name = 'console'
            call_pattern = 'get_console()'
        elif pattern == 'repeated_get_hud':
            cache_line = 'local hud = get_hud()'
            new_name = 'hud'
            call_pattern = 'get_hud()'
        elif pattern == 'repeated_game_ini':
            cache_line = 'local g_ini = game_ini()'
            new_name = 'g_ini'
            call_pattern = 'game_ini()'
        elif pattern == 'repeated_getFS':
            cache_line = 'local fs = getFS()'
            new_name = 'fs'
            call_pattern = 'getFS()'
        elif pattern == 'repeated_level_name':
            cache_line = 'local level_name = level.name()'
            new_name = 'level_name'
            call_pattern = 'level.name()'
        elif pattern.endswith('_story_id()') or pattern.endswith('_section()') or pattern.endswith('_id()') or pattern.endswith('_clsid()'):
            # dynamic method caching: repeated_obj_section(), repeated_item_id(), etc
            # extract object name and method from pattern: repeated_obj_section() -> obj, section
            # pattern format: repeated_{objname}_{method}()
            # NOTE: story_id must be checked before id since _id() is suffix of _story_id()
            # NOTE: Use non-greedy (.+?) to avoid capturing part of method name
            match = re.match(r'repeated_(.+?)_(story_id|section|clsid|id)\(\)$', pattern)
            if not match:
                return
            sanitized_obj_name = match.group(1)
            method_name = match.group(2)
            
            # get original object name from details if available (e.g. "self.object:id()")
            original_call = details.get('original_call', '') if details else ''
            if original_call and ':' in original_call:
                # extract original object name: "self.object:id()" -> "self.object"
                real_obj_name = original_call.split(':')[0]
            else:
                # fallback: try to restore dots from underscores for common patterns
                if sanitized_obj_name.startswith('self_'):
                    real_obj_name = 'self.' + sanitized_obj_name[5:]
                else:
                    real_obj_name = sanitized_obj_name
            
            # SAFETY CHECK: skip if object is an indexed expression (e.g., t[a], arr[i])
            # These can't be converted to valid Lua variable names
            if '[' in real_obj_name or ']' in real_obj_name:
                return
            
            # generate cache variable name (always use sanitized for variable)
            if method_name == 'section':
                new_name = f'{sanitized_obj_name}_sec'
            elif method_name == 'id':
                new_name = f'{sanitized_obj_name}_id'
            elif method_name == 'clsid':
                new_name = f'{sanitized_obj_name}_cls'
            elif method_name == 'story_id':
                new_name = f'{sanitized_obj_name}_sid'
            else:
                new_name = f'{sanitized_obj_name}_{method_name}'
            
            cache_line = f'local {new_name} = {real_obj_name}:{method_name}()'
            call_pattern = f'{real_obj_name}:{method_name}()'
        else:
            return

        # pattern to detect exact cache declaration (local obj =, not local obj1 =)
        cache_decl_pattern = rf'\blocal\s+{re.escape(new_name)}\s*='

        # check if first call is already a cache declaration for THIS pattern
        # i.e., "local obj = level.object_by_id(...)" where obj is the cache var
        first_call = calls[0]
        first_line_start, first_line_end = self._get_line_span(first_call.line)
        is_already_cached = False
        cache_indent = None

        if first_line_start is not None:
            first_line = self.source[first_line_start:first_line_end]
            if re.search(cache_decl_pattern, first_line) and call_pattern in first_line:
                is_already_cached = True
                cache_indent = self._get_indent_at_line(first_call.line)

        # insert cache if not already present
        if not is_already_cached:
            insert_pos = self._get_line_start(first_call.line)
            if insert_pos is None:
                return

            indent = self._get_indent_at_line(first_call.line)
            
            # Bug #33 fix: check if insertion point is inside a multi-line comment
            # scan from start of file to insertion point for --[[ and ]]
            text_before = self.source[:insert_pos]
            mlc_open = text_before.rfind('--[[')
            mlc_close = text_before.rfind(']]')
            if mlc_open != -1 and (mlc_close == -1 or mlc_close < mlc_open):
                # we're inside a multi-line comment, skip this optimization
                return
            
            # is this a method cache (obj:method()) vs global cache (func())
            is_method_cache = ':' in call_pattern

            # check if first call is inside a table constructor or function call arguments
            # look for unbalanced { or ( in lines before this one within scope
            if scope and hasattr(scope, 'start_line'):
                brace_depth = 0
                paren_depth = 0
                has_loop_before_first_call = False
                has_branch_between_calls = False

                for check_line in range(scope.start_line, first_call.line + 1):
                    ls, le = self._get_line_span(check_line)
                    if ls is not None:
                        line_text = self.source[ls:le]
                        # skip comments
                        if '--' in line_text:
                            line_text = line_text[:line_text.find('--')]
                        # skip strings (simple approach - just count outside quotes)
                        in_string = False
                        clean_line = ""
                        i = 0
                        while i < len(line_text):
                            c = line_text[i]
                            if c in ('"', "'") and not in_string:
                                in_string = c
                            elif c == in_string and (i == 0 or line_text[i-1] != '\\'):
                                in_string = False
                            elif not in_string:
                                clean_line += c
                            i += 1
                        
                        brace_depth += clean_line.count('{') - clean_line.count('}')
                        paren_depth += clean_line.count('(') - clean_line.count(')')

                        # check for loop constructs before first call
                        if check_line < first_call.line:
                            stripped = line_text.strip().lower()
                            if stripped.startswith(('for ', 'while ', 'repeat')):
                                has_loop_before_first_call = True

                if brace_depth > 0:
                    return  # inside table constructor, skip optimization
                
                if paren_depth > 0:
                    return  # inside function call arguments, skip optimization

                # SAFETY CHECK: detect nil-guarded method calls
                # Pattern: "obj and obj:method()" or "if obj and ... obj:method()"
                # These rely on short-circuit evaluation for safety - caching breaks this
                if is_method_cache:
                    first_ls, first_le = self._get_line_span(first_call.line)
                    if first_ls is not None:
                        first_line_text = self.source[first_ls:first_le]
                        # extract object name from call_pattern: "obj:method()" -> "obj"
                        obj_name = call_pattern.split(':')[0]
                        
                        # check if this line has pattern: "obj and" before "obj:method"
                        call_pos = first_line_text.find(call_pattern)
                        if call_pos > 0:
                            before_call = first_line_text[:call_pos]
                            nil_guard_pattern = rf'\b{re.escape(obj_name)}\s+and\b'
                            if re.search(nil_guard_pattern, before_call):
                                # object is nil-guarded, skip caching to preserve safety
                                return

                # check if calls span different blocks
                # look for else/elseif/end between first and last call
                last_call = calls[-1]
                if last_call.line > first_call.line:
                    first_indent = self._get_indent_at_line(first_call.line)
                    first_indent_len = len(first_indent) if first_indent else 0
                    
                    for check_line in range(first_call.line + 1, last_call.line + 1):
                        cls, cle = self._get_line_span(check_line)
                        if cls is not None:
                            check_text = self.source[cls:cle]
                            check_stripped = check_text.lstrip()
                            check_indent_len = len(check_text) - len(check_stripped)
                            
                            # if else/elseif/end at same or shallower indent, calls are in different blocks
                            if check_indent_len <= first_indent_len:
                                first_word = check_stripped.split()[0] if check_stripped.split() else ''
                                if first_word in ('else', 'elseif', 'end'):
                                    has_branch_between_calls = True
                                    break

                if (has_loop_before_first_call or has_branch_between_calls) and last_call.line > first_call.line:
                    if is_method_cache:
                        # for method caching, skip if branches exist - too risky to hoist
                        return
                    
                    # insert right after function declaration
                    new_insert_pos = self._get_line_start(scope.start_line + 1)
                    if new_insert_pos is None:
                        return
                    
                    # Bug #33 fix: check if new insertion point is inside a multi-line comment
                    text_before_new = self.source[:new_insert_pos]
                    mlc_open_new = text_before_new.rfind('--[[')
                    mlc_close_new = text_before_new.rfind(']]')
                    if mlc_open_new != -1 and (mlc_close_new == -1 or mlc_close_new < mlc_open_new):
                        # new position is inside a multi-line comment, skip this optimization
                        return
                    
                    insert_pos = new_insert_pos
                    # use indent from first call (which is inside the function body)
                    # but reduced by one level since first_call may be inside if/for
                    call_indent = self._get_indent_at_line(first_call.line)
                    if call_indent and len(call_indent) > 0:
                        # detect indent char (tab or spaces)
                        if call_indent[0] == '\t':
                            indent = '\t'  # one tab for function body
                        else:
                            # count spaces per indent level (usually 4 or 2)
                            indent = call_indent[:len(call_indent)//2] if len(call_indent) >= 2 else call_indent
                    else:
                        indent = '\t'

            self.edits.append(SourceEdit(
                start_char=insert_pos,
                end_char=insert_pos,
                replacement=f'{indent}{cache_line}\n',
                priority=100,
            ))

        # replace usages - skip only lines that are the cache declaration itself
        for call in calls:
            line_start, line_end = self._get_line_span(call.line)
            if line_start is not None:
                line = self.source[line_start:line_end]
                # only skip if this is THE cache declaration (local obj = pattern)
                if re.search(cache_decl_pattern, line) and call_pattern in line:
                    continue

            # if cache already existed (we didn't insert it), check if we're in same scope
            # by looking for else/elseif/end at cache indent level between cache and call
            if is_already_cached and cache_indent is not None and call.line > first_call.line:
                in_sibling_scope = False
                cache_indent_len = len(cache_indent)

                for check_line in range(first_call.line + 1, call.line):
                    cls, cle = self._get_line_span(check_line)
                    if cls is not None:
                        check_text = self.source[cls:cle]
                        check_stripped = check_text.lstrip()
                        check_indent_len = len(check_text) - len(check_stripped)

                        # if we see else/elseif/end at same or shallower indent, scope changed
                        if check_indent_len <= cache_indent_len:
                            first_word = check_stripped.split()[0] if check_stripped.split() else ''
                            if first_word in ('else', 'elseif', 'end'):
                                in_sibling_scope = True
                                break

                if in_sibling_scope:
                    continue  # skip - we're in a sibling scope

            node = call.node
            if not node:
                continue

            # get span for the call expression
            start, end = self._get_node_span(node)
            if start is None:
                continue

            self.edits.append(SourceEdit(
                start_char=start,
                end_char=end,
                replacement=new_name,
            ))


    # Position helpers using AST tokens

    def _get_node_span(self, node) -> Tuple[Optional[int], Optional[int]]:
        """Get character span (start, end) for an AST node."""
        from luaparser.astnodes import Call, Index, Invoke, Name

        # for Call nodes with Index func (like table.insert),
        # the first_token might not include the base object
        if isinstance(node, Call):
            func = getattr(node, 'func', None)

            # check if first_token looks like it's just '(' - means we need to find the func name
            first = getattr(node, 'first_token', None)
            first_str = str(first) if first else ''

            if "='('" in first_str or "=''" in first_str:
                # the call's first_token is just the paren, we need to find the function name
                # search backwards from paren position to find the identifier
                paren_start = self._parse_token_start(first_str)
                if paren_start is not None:
                    # find the identifier before the paren
                    pos = paren_start - 1
                    # skip whitespace
                    while pos >= 0 and self.source[pos] in ' \t\n':
                        pos -= 1
                    # find end of identifier
                    end_of_name = pos + 1
                    # find start of identifier
                    while pos >= 0 and (self.source[pos].isalnum() or self.source[pos] == '_'):
                        pos -= 1
                    start = pos + 1

                    # end is the closing paren
                    last = getattr(node, 'last_token', None)
                    end = self._parse_token_end(str(last)) if last else None

                    if start is not None and end is not None:
                        return start, end

            if isinstance(func, Index):
                # get the start from the base value
                value = getattr(func, 'value', None)
                if value:
                    value_first = getattr(value, 'first_token', None)
                    if value_first and str(value_first) != 'None':
                        start = self._parse_token_start(str(value_first))
                    else:
                        # fallback to finding base before the dot
                        func_start = self._parse_token_start(
                            str(func.first_token)) if func.first_token else None
                        if func_start is not None:
                            # search backwards for the base name
                            pos = func_start - 1
                            while pos >= 0 and self.source[pos] in ' \t':
                                pos -= 1
                            # find start of identifier
                            while pos >= 0 and (
                                    self.source[pos].isalnum() or self.source[pos] == '_'):
                                pos -= 1
                            start = pos + 1
                        else:
                            start = None
                else:
                    start = self._parse_token_start(
                        str(node.first_token)) if node.first_token else None

                # end from the call's last_token
                last = getattr(node, 'last_token', None)
                end = self._parse_token_end(str(last)) if last else None

                return start, end

        # default: use first/last tokens directly
        first = getattr(node, 'first_token', None)
        last = getattr(node, 'last_token', None)

        if not first or not last or str(first) == 'None' or str(last) == 'None':
            return None, None

        start = self._parse_token_start(str(first))
        end = self._parse_token_end(str(last))

        return start, end

    def _get_call_func_span(self, node, func_name: str) -> Tuple[Optional[int], Optional[int]]:
        """Get span for the function name part of a call node."""
        from luaparser.astnodes import Index, Name

        func_node = getattr(node, 'func', None)

        # for module.func patterns (like bit.band), need special handling
        if '.' in func_name and func_node and isinstance(func_node, Index):
            # get the full span from base name to func name
            # Index.value is the base (e.g., "bit")
            # Index.idx is the function (e.g., "band")
            value = getattr(func_node, 'value', None)
            idx = getattr(func_node, 'idx', None)

            # try to get start from value's token, or search backwards from Index token
            start = None
            if value:
                value_first = getattr(value, 'first_token', None)
                if value_first and str(value_first) != 'None':
                    start = self._parse_token_start(str(value_first))

            if start is None:
                # fallback: search backwards from the dot/bracket to find base name
                func_first = getattr(func_node, 'first_token', None)
                if func_first and str(func_first) != 'None':
                    dot_pos = self._parse_token_start(str(func_first))
                    if dot_pos is not None and dot_pos > 0:
                        # search backwards for identifier start
                        pos = dot_pos - 1
                        while pos >= 0 and self.source[pos] in ' \t':
                            pos -= 1
                        while pos >= 0 and (self.source[pos].isalnum() or self.source[pos] == '_'):
                            pos -= 1
                        start = pos + 1

            # get end from idx's last token or Index's last token
            end = None
            func_last = getattr(func_node, 'last_token', None)
            if func_last and str(func_last) != 'None':
                end = self._parse_token_end(str(func_last))

            if start is not None and end is not None:
                return start, end

        # for bare names, use the func node span directly
        if func_node and not isinstance(func_node, Index):
            start, end = self._get_node_span(func_node)
            if start is not None:
                return start, end

        # fallback: find in source
        node_start, node_end = self._get_node_span(node)
        if node_start is None:
            return None, None

        # find func_name within the node text
        text = self.source[node_start:node_end]

        # for bare names like "pairs", find exact match
        if '.' not in func_name:
            # find the name followed by (
            pos = 0
            while pos < len(text):
                idx = text.find(func_name, pos)
                if idx == -1:
                    break
                # check it's a word boundary
                before_ok = (idx == 0 or not text[idx - 1].isalnum() and text[idx - 1] != '_')
                after_idx = idx + len(func_name)
                after_ok = (after_idx >= len(text)
                            or not text[after_idx].isalnum() and text[after_idx] != '_')
                if before_ok and after_ok:
                    return node_start + idx, node_start + idx + len(func_name)
                pos = idx + 1
        else:
            # for module.func, find the whole thing
            idx = text.find(func_name)
            if idx != -1:
                return node_start + idx, node_start + idx + len(func_name)

        return None, None

    def _parse_token_start(self, token_str: str) -> Optional[int]:
        """Parse start character position from token string."""
        # Format: [@index,start:end='text',<type>,line:col]
        # Positions appear to be 0-indexed
        match = re.match(r"\[@\d+,(\d+):\d+='", token_str)
        if match:
            return int(match.group(1))
        return None

    def _parse_token_end(self, token_str: str) -> Optional[int]:
        """Parse end character position from token string."""
        # End position is inclusive, we want exclusive, so add 1
        match = re.match(r"\[@\d+,\d+:(\d+)='", token_str)
        if match:
            return int(match.group(1)) + 1
        return None

    def _get_line_span(self, line_num: int) -> Tuple[Optional[int], Optional[int]]:
        """Get character span for a line (1-indexed), including newline."""
        lines = self.source.split('\n')
        if line_num < 1 or line_num > len(lines):
            return None, None

        start = sum(len(l) + 1 for l in lines[:line_num - 1])
        end = start + len(lines[line_num - 1])

        # include newline if not last line
        if line_num < len(lines):
            end += 1

        return start, end

    def _get_line_start(self, line_num: int) -> Optional[int]:
        """Get character position of line start."""
        start, _ = self._get_line_span(line_num)
        return start

    def _get_line_end(self, line_num: int) -> Optional[int]:
        """Get character position of line end (before newline)."""
        lines = self.source.split('\n')
        if line_num < 1 or line_num > len(lines):
            return None

        pos = sum(len(l) + 1 for l in lines[:line_num - 1])
        pos += len(lines[line_num - 1])
        return pos

    def _get_indent_at_line(self, line_num: int) -> str:
        """Get indentation at a line."""
        lines = self.source.split('\n')
        if 0 < line_num <= len(lines):
            line = lines[line_num - 1]
            stripped = line.lstrip()
            return line[:len(line) - len(stripped)]
        return ''

    def _apply_edits(self) -> str:
        """Apply all edits and return new source."""
        if not self.edits:
            return self.source

        # sort by priority descending, then position descending
        self.edits.sort(key=lambda e: (-e.priority, -e.start_char))

        # remove overlapping and duplicate edits (keep higher priority / earlier in sort)
        filtered = []
        covered_ranges: List[Tuple[int, int]] = []
        seen_insertions: set = set()  # track (position, replacement) for pure insertions

        for edit in self.edits:
            overlaps = False
            
            # check for duplicate insertions at same position
            if edit.start_char == edit.end_char:
                insertion_key = (edit.start_char, edit.replacement)
                if insertion_key in seen_insertions:
                    continue  # skip duplicate insertion
                seen_insertions.add(insertion_key)
            
            for start, end in covered_ranges:
                # check for overlap
                if edit.start_char < end and edit.end_char > start:
                    overlaps = True
                    break

            if not overlaps:
                filtered.append(edit)
                if edit.start_char != edit.end_char:  # don't track insertions as covered
                    covered_ranges.append((edit.start_char, edit.end_char))

        # apply edits from end to start (so positions don't shift)
        result = self.source
        for edit in sorted(filtered, key=lambda e: -e.start_char):
            result = result[:edit.start_char] + edit.replacement + result[edit.end_char:]

        return result


def transform_file(file_path: Path, backup: bool = True, dry_run: bool = False,
                   fix_debug: bool = False, fix_yellow: bool = False,
                   experimental: bool = False, fix_nil: bool = False,
                   remove_dead_code: bool = False) -> Tuple[bool, str, int]:
    """Convenience function to transform a file. Returns (modified, content, edit_count)."""
    transformer = ASTTransformer()
    return transformer.transform_file(file_path, backup, dry_run, fix_debug, fix_yellow, experimental, fix_nil, remove_dead_code)
